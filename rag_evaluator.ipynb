{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1400e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "import tools.rag_functions as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6506d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"models/models_test.json\"\n",
    "documents_path = \"dataset/texts\"\n",
    "qa_eval_set_path = \"dataset/qa/qa_eval_set.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b2db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models = rf.list_models(models_path, models_type=\"embedding_models\")\n",
    "generative_models = rf.list_models(models_path, models_type=\"generative_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af05457",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_eval_set = rf.load_json(qa_eval_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1a8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = rf.load_texts(documents_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6bb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data = rf.chunk_texts(texts, chunk_size=128, overlap=10)\n",
    "chunk_names, text_chunks = rf.dict_to_kv_lists(chunk_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e30706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb import Settings\n",
    "\n",
    "class Vectorizator:\n",
    "    def __init__(self, documents, ids):\n",
    "        self.documents = documents\n",
    "        self.ids = ids\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=\"chroma_data/\",\n",
    "            settings=Settings(allow_reset=True)\n",
    "        )\n",
    "        \n",
    "    def get_or_load_model_collection(self, model_family, embedding_model_name):\n",
    "        collection_name = f\"collection_by_{embedding_model_name}\"\n",
    "        ef = rf.universal_ef(model_family, embedding_model_name)            \n",
    "        try:\n",
    "            self.load_collection(collection_name, ef)\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"Collection for this model doesn't exist, database will be populated instead.\")\n",
    "            self.populate_db(collection_name, ef)\n",
    "\n",
    "    def populate_db(self, collection_name, ef):\n",
    "        try:\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=collection_name, \n",
    "                embedding_function=ef()\n",
    "            )\n",
    "            self.collection.upsert(\n",
    "                documents=self.documents,\n",
    "                ids=self.ids\n",
    "            )\n",
    "            print(f\"Documents successfully embedded and saved to a collection.\")\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"An unknown error occurred while saving:\\n{err}\")\n",
    "            raise\n",
    "             \n",
    "    def load_collection(self, collection_name, ef):\n",
    "        self.collection = self.client.get_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=ef()\n",
    "        )\n",
    "        print(f\"Documents successfully loaded as a collection.\")\n",
    "\n",
    "\n",
    "    def clear(self, whole=False, embedding_model_name=None):\n",
    "        if whole:\n",
    "            self.client.reset()\n",
    "        else:\n",
    "            try:\n",
    "                collection_name = f\"collection_by_{embedding_model_name}\"\n",
    "                self.client.delete_collection(name=collection_name)\n",
    "            except Exception as err:\n",
    "                print(f\"An error occurred:\\n{err}\")\n",
    "\n",
    "            \n",
    "    def get_results(self, question, n_results=3):\n",
    "        outputs = self.collection.query(\n",
    "            query_texts=[question], \n",
    "            n_results=n_results\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2c1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizator = Vectorizator(\n",
    "    documents=text_chunks,\n",
    "    ids=chunk_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74bf4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_config.clients_api import clients\n",
    "\n",
    "class GenerativeModelClient:\n",
    "    def __init__(self, provider):\n",
    "        for provider_name, client_function in clients:\n",
    "            if provider == provider_name:\n",
    "                client = client_function()\n",
    "                client = clients[provider]()\n",
    "        self.client = client\n",
    "        return client\n",
    "\n",
    "    def generate_answer(self, prompt, model_name):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        self.answer = response.choices[0].message.content\n",
    "        return self.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"em1\" : {\n",
    "        \"llama\" : {\n",
    "            {\n",
    "                \"question1\" : answer_eval_results, \n",
    "                \"question2\" : answer_eval_results\n",
    "            }\n",
    "        },\n",
    "        \"gpt\" : {\n",
    "            {\n",
    "                \"question1\" : answer_eval_results, \n",
    "                \"question2\" : answer_eval_results\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"em2\" : {\n",
    "        \"llama\" : {\n",
    "            {\n",
    "                \"question1\" : answer_eval_results, \n",
    "                \"question2\" : answer_eval_results\n",
    "            }\n",
    "        },\n",
    "        \"gpt\" : {\n",
    "            {\n",
    "                \"question1\" : answer_eval_results, \n",
    "                \"question2\" : answer_eval_results\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "296a6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence_transformers_embedding': ['all-MiniLM-L6-v2', 'paraphrase-multilingual-mpnet-base-v2']}\n"
     ]
    }
   ],
   "source": [
    "print(embedding_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab68f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "paraphrase-multilingual-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "for model_family in embedding_models:\n",
    "    for embedding_model_name in embedding_models[model_family]:\n",
    "        print(embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee176ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on sentence_transformers_embedding...\n",
      "Collection for this model doesn't exist, database will be populated instead.\n",
      "Documents successfully embedded and saved to a collection.\n",
      "too many values to unpack (expected 2)\n",
      "Working on sentence_transformers_embedding...\n",
      "Documents successfully loaded as a collection.\n",
      "too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "from model_config.prompt_template import inject_prompt\n",
    "from tests.similarity_calculating_test import SimilarityCalculator\n",
    "\n",
    "all_combs_results = {}\n",
    "\n",
    "\n",
    "for model_family in embedding_models:\n",
    "    for embedding_model_name in embedding_models[model_family]:\n",
    "        print(f\"Working on {embedding_model_name}...\")\n",
    "        try:\n",
    "            vectorizator.get_or_load_model_collection(model_family, embedding_model_name)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            break # continue with next model\n",
    "\n",
    "        all_combs_results[embedding_model_name] = {}\n",
    "        for provider in generative_models:\n",
    "            try:\n",
    "                chatbot = GenerativeModelClient(provider)\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                break # continue with next provider, probably something wrong with API\n",
    "\n",
    "            for generative_model_name in provider:\n",
    "                \n",
    "                all_combs_results[embedding_model_name][generative_model_name] = {}\n",
    "                if generation_failed:\n",
    "                        break\n",
    "                for i in range(len(qa_eval_set)):\n",
    "                    question = qa_eval_set[i][\"question\"]\n",
    "                    expected_answer = qa_eval_set[i][\"answer\"]\n",
    "\n",
    "                    outputs = vectorizator.get_results(question)\n",
    "                    context = \"\\n\\n\".join(outputs[\"documents\"][0])\n",
    "                    prompt = inject_prompt(context, question)\n",
    "                    try:\n",
    "                        generated_answer = chatbot.generate_answer(prompt, generative_model_name)\n",
    "                    except Exception as err:\n",
    "                        print(err)\n",
    "                        generation_failed = True\n",
    "                        # delete the generative_model_name from the dict\n",
    "                        break\n",
    "                    \n",
    "                    similaritator = SimilarityCalculator(expected_answer, generated_answer)\n",
    "                    answer_eval_results = similaritator.compare_texts()\n",
    "                    all_combs_results[embedding_model_name][generative_model_name][question] = answer_eval_results\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
