{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rag_functions as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import google.auth\n",
    "from chromadb.api.types import (\n",
    "    Documents,\n",
    "    EmbeddingFunction,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "import vertexai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all data – documents, questions and list of the right answers. Segment documents into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = \"/Users/sladkydrevo/opt/baka/dataset/texts\"\n",
    "texts = rf.load_texts(DATA_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_counts, chunk_data = rf.chunk_texts(texts, chunk_size=128, overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_names, text_chunks = rf.split_dict_data(chunk_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTIONS_FOLDER_PATH = \"/Users/sladkydrevo/opt/baka/dataset/questions\"\n",
    "questions_data = rf.load_texts(QUESTIONS_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = rf.convert_questions_dict(questions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_names, question_texts = rf.split_dict_data(questions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_answers_path = \"/Users/sladkydrevo/opt/baka/right_answers.txt\"\n",
    "right_answers = rf.load_right_answers(right_answers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/Users/sladkydrevo/opt/baka/MODELS_RESULTS.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a class for testing sentence transformers and other embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaModelTester:\n",
    "    def __init__(self, col_name, documents, ids, query_texts, question_names, right_answers, results_path, n_results=5):\n",
    "        self.col_name = col_name\n",
    "        self.documents = documents\n",
    "        self.ids = ids\n",
    "        self.query_texts = query_texts\n",
    "        self.question_names = question_names\n",
    "        self.right_answers = right_answers\n",
    "        self.results_path = results_path\n",
    "        self.n_results = n_results\n",
    "        self.chroma_client = chromadb.Client()\n",
    "        self.results = {}\n",
    "        \n",
    "    def _test_model(self, model_name, ef):\n",
    "        try:\n",
    "            self.chroma_client.delete_collection(self.col_name)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        print(f\"Testing model {model_name}...\")\n",
    "        collection = self.chroma_client.create_collection(name=self.col_name, embedding_function=ef)\n",
    "        collection.upsert(\n",
    "            documents=self.documents,\n",
    "            ids=self.ids\n",
    "        )\n",
    "        print(f\"Documents embedded and inserted to the collection.\")\n",
    "        \n",
    "        outputs = collection.query(\n",
    "            query_texts=self.query_texts, \n",
    "            n_results=self.n_results\n",
    "        )\n",
    "                \n",
    "        answers = rf.get_top_n_from_db(outputs, question_names, question_texts, n=self.n_results)\n",
    "        rank_table = rf.get_rank_table(answers, self.right_answers, self.n_results)\n",
    "        match_results = rf.get_match_count(rank_table)\n",
    "        tops = rf.get_top_accuracies(match_results, questions)   \n",
    "        rf.write_to_csv_top_5(self.results_path, results=tops, model_name=model_name)\n",
    "        \n",
    "        self.results[model_name] = {\n",
    "            \"model_name\" : model_name,\n",
    "            \"outputs\": outputs,\n",
    "            \"answers\": answers,\n",
    "            \"match_results\": match_results,\n",
    "            \"tops\": tops\n",
    "        }\n",
    "        \n",
    "    def test_sentence_transformers(self, sentence_transformers_list):\n",
    "        for model_name in sentence_transformers_list:\n",
    "            try:\n",
    "                ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=model_name)\n",
    "                self._test_model(model_name, ef)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to test {model_name}: {e}\")\n",
    "            \n",
    "    def test_api_models(self, efs_dict):\n",
    "        for model_name, ef in efs_dict.items():\n",
    "            try:\n",
    "                self._test_model(model_name, ef())  \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to test {model_name}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List sentence transformers for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformers = [\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"distiluse-base-multilingual-cased-v1\",\n",
    "    \"distiluse-base-multilingual-cased-v2\",\n",
    "    \"multi-qa-MiniLM-L6-cos-v1\",\n",
    "    \"multi-qa-distilbert-cos-v1\",\n",
    "    \"multi-qa-mpnet-base-dot-v1\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define embedding functions for other models and put them into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexAIEmbeddingFunction(EmbeddingFunction[Documents]):\n",
    "    def __init__(self, project_id, location, model_name, dimensionality=3072):\n",
    "        creds, _ = google.auth.default(quota_project_id=project_id)\n",
    "        vertexai.init(project=project_id, location=location, credentials=creds)\n",
    "        \n",
    "        self.model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "        self.dimensionality = dimensionality\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            embedding = self.model.get_embeddings([text])\n",
    "            embeddings.append(embedding[0].values)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_embedding(model_name):\n",
    "    cohere_ef = embedding_functions.CohereEmbeddingFunction(\n",
    "        api_key=os.environ[\"COHERE_API_KEY\"], \n",
    "        model_name=model_name\n",
    "    )\n",
    "    return cohere_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_embedding(model_name):\n",
    "    vertex_ef = VertexAIEmbeddingFunction(\n",
    "        project_id=\"nodal-vigil-455211-t6\",\n",
    "        location=\"us-central1\",\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    return vertex_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genai_embedding(model_name):\n",
    "    genai_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "        api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return genai_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jina_embedding(model_name):\n",
    "    jina_ef = embedding_functions.JinaEmbeddingFunction(\n",
    "        api_key=os.environ[\"JINA_API_KEY\"],\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    return jina_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_embedding(model_name):\n",
    "    ollama_ef = embedding_functions.OllamaEmbeddingFunction(\n",
    "        url=\"http://127.0.0.1:11434/api/embeddings\",\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    return ollama_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_embedding(model_name):\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return openai_ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models = {\n",
    "    \"MixedBreadAI: mxbai-embed-large\" : lambda: ollama_embedding(\"mxbai-embed-large\"),\n",
    "    \"Snowflake: snowflake-arctic-embed\" : lambda: ollama_embedding(\"snowflake-arctic-embed\"),\n",
    "    \"NomicAI: nomic-embed-text\" : lambda: ollama_embedding(\"nomic-embed-text\"),\n",
    "    #\"Llama: granite-embedding\" : lambda: ollama_embedding(\"granite-embedding\"), # list index out of range?\n",
    "    \"Cohere: embed-multilingual-v2.0\" : lambda: cohere_embedding(\"embed-multilingual-v2.0\"),    \n",
    "    \"Cohere: embed-multilingual-v3.0\" : lambda: cohere_embedding(\"embed-multilingual-v3.0\"),\n",
    "    \"Cohere: embed-multilingual-light-v3.0\" : lambda: cohere_embedding(\"embed-multilingual-light-v3.0\"),\n",
    "    \"Jina: jina-clip-v2\" : lambda: jina_embedding(\"jina-clip-v2\"),\n",
    "    \"Jina: jina-embeddings-v3\" : lambda: jina_embedding(\"jina-embeddings-v3\"),\n",
    "    #\"Jina: jina-colbert-v2\" : lambda: jina_embedding(\"jina-colbert-v2\"), # not available to use for /v1/embeddings\n",
    "    #\"Jina: jina-reranker-v2-base-multilingual\" : lambda: jina_embedding(\"jina-reranker-v2-base-multilingual\"), # not available to use for /v1/embeddings\n",
    "    \"Google: text-embedding-004\" : lambda: genai_embedding(\"models/text-embedding-004\"),\n",
    "    \"Google Vertex AI: text-multilingual-embedding-002\" : lambda: vertex_embedding(\"text-multilingual-embedding-002\"),\n",
    "    #\"Google Vertex AI: text-embedding-large-exp-03-07\" : lambda: vertex_embedding(\"text-embedding-large-exp-03-07\"), # neodpovídá počet požadavků za minutu\n",
    "    \"OpenAI: text-embedding-ada-002\" : lambda: openai_embedding(\"text-embedding-ada-002\"),\n",
    "    \"OpenAI: text-embedding-3-small\" : lambda: openai_embedding(\"text-embedding-3-small\"),\n",
    "    \"OpenAI: text-embedding-3-large\" : lambda: openai_embedding(\"text-embedding-3-large\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ChromaModelTester(\n",
    "    col_name=\"dataset\",\n",
    "    documents=text_chunks, \n",
    "    ids=chunk_names,\n",
    "    query_texts=question_texts,\n",
    "    question_names=question_names,\n",
    "    right_answers=right_answers, \n",
    "    results_path=\"/Users/sladkydrevo/opt/baka/MODELS_RESULTS.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test multilingual Sentence transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model all-MiniLM-L6-v2...\n",
      "Documents embedded and inserted to the collection.\n",
      "Results successfully recorded. Model name: all-MiniLM-L6-v2 Results: [0.15, 0.25, 0.3]\n"
     ]
    }
   ],
   "source": [
    "tester.test_sentence_transformers(sentence_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test multilingual embedding models through API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.test_api_models(embedding_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
